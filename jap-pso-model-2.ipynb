{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14124209,"sourceType":"datasetVersion","datasetId":8867230}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom glob import glob\nimport warnings\nfrom scipy.fft import fft, fftfreq\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport json\n\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def calculate_rms_error(healthy_signal,damaged_signal):\n    \"\"\"Calculate RMS error between healthy and damaged signals\"\"\"\n    return np.sqrt(np.mean((health_signal-damaged_signal)**2))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_dominant_frequency(signal_data,sampling_data=100):\n    \"\"\"Extract Dominant Frequency from signal using FFT\"\"\"\n    n= len(signal_data)\n    yf = fft(signal_data)\n    xf = fftreq(n,1/sampling_rate)\n\n    positive_freq_idx = xf>0\n    xf_pos = xf[positive_freq_idx]\n    yf_pos = np.abs(yf[positive_freq_idx])\n\n    dominant_idx = np.argmax(yf_pos)\n    return xf_pos[dominant_idx]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def calculate_frequency_shift(health_signal,damaged_signal,sampling_rate=100):\n    \"\"\"Calculate frequency shift between healthy and damaged signals\"\"\"\n    healthy_freq = extract_dominant_frequency(healthy_signal,sampling_rate)\n    damaged_freq = extract_dominant_frequency(damaged_signal,sampling_rate)\n    return abs(damaged_freq-healthy_freq)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# GPU-ACCELERATED PSO IMPLEMENTATION","metadata":{}},{"cell_type":"code","source":"class BridgePSO:\n    \"\"\"GPU-accelerated Particle Swarm Optimization for damage localization\"\"\"\n    \n    def __init__(self, n_particles=50, n_elements=3, bounds=(0.1, 1.0), \n                 c1=0.5, c2=0.3, w=0.9, device='cuda'):\n        \"\"\"\n        Initialize PSO optimizer\n        \n        Args:\n            n_particles: Number of particles in swarm\n            n_elements: Number of structural elements (sensors)\n            bounds: Tuple of (lower, upper) bounds for stiffness reduction\n            c1: Cognitive parameter\n            c2: Social parameter\n            w: Inertia weight\n            device: 'cuda' or 'cpu'\n        \"\"\"\n        self.n_particles = n_particles\n        self.n_elements = n_elements\n        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')\n        \n        # PSO parameters\n        self.c1 = c1\n        self.c2 = c2\n        self.w = w\n        self.bounds = bounds\n        \n        # Initialize particles (stiffness reduction factors for each element)\n        # 1.0 = healthy, < 1.0 = damaged\n        self.positions = torch.rand(n_particles, n_elements, device=self.device)\n        self.positions = self.positions * (bounds[1] - bounds[0]) + bounds[0]\n        \n        # Initialize velocities\n        self.velocities = torch.randn(n_particles, n_elements, device=self.device) * 0.1\n        \n        # Best positions\n        self.personal_best_positions = self.positions.clone()\n        self.personal_best_scores = torch.full((n_particles,), float('inf'), device=self.device)\n        \n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n        # History tracking\n        self.history = {\n            'global_best_scores': [],\n            'mean_scores': [],\n            'std_scores': []\n        }\n    \n    def apply_damage_to_signals(self, healthy_signals, damage_factors):\n        \"\"\"\n        Apply damage factors to healthy signals to simulate damaged response\n        \n        Args:\n            healthy_signals: Tensor of shape (n_sensors, signal_length)\n            damage_factors: Tensor of shape (n_sensors,) with values in [0, 1]\n        \n        Returns:\n            Simulated damaged signals\n        \"\"\"\n        # Simple damage model: reduce amplitude and shift frequency\n        # This is a simplified physical model\n        damaged = healthy_signals.clone()\n        \n        for i, factor in enumerate(damage_factors):\n            # Amplitude reduction\n            damaged[i] *= factor\n            \n            # Add noise proportional to damage severity\n            noise_level = (1 - factor) * 0.1\n            damaged[i] += torch.randn_like(damaged[i]) * noise_level * damaged[i].std()\n        \n        return damaged\n    \n    def fitness_function(self, particles, healthy_signals, observed_signals):\n        \"\"\"\n        Evaluate fitness for all particles (GPU-accelerated)\n        \n        Args:\n            particles: Tensor of shape (n_particles, n_elements)\n            healthy_signals: Tensor of shape (n_sensors, signal_length)\n            observed_signals: Tensor of shape (n_sensors, signal_length)\n        \n        Returns:\n            Fitness scores for each particle (lower is better)\n        \"\"\"\n        batch_size = particles.shape[0]\n        n_sensors = healthy_signals.shape[0]\n        \n        fitness_scores = torch.zeros(batch_size, device=self.device)\n        \n        for i in range(batch_size):\n            # Simulate damaged response with current particle's damage factors\n            simulated = self.apply_damage_to_signals(healthy_signals, particles[i])\n            \n            # Calculate RMS error between simulated and observed\n            error = torch.sqrt(torch.mean((simulated - observed_signals) ** 2))\n            \n            # Add regularization to prevent trivial solutions (all damaged)\n            # Encourage sparsity in damage\n            sparsity_penalty = torch.sum(1.0 - particles[i]) * 0.01\n            \n            fitness_scores[i] = error + sparsity_penalty\n        \n        return fitness_scores\n    \n    def update(self, fitness_scores):\n        \"\"\"Update particle positions and velocities\"\"\"\n        # Update personal bests\n        improved = fitness_scores < self.personal_best_scores\n        self.personal_best_scores[improved] = fitness_scores[improved]\n        self.personal_best_positions[improved] = self.positions[improved].clone()\n        \n        # Update global best\n        min_idx = torch.argmin(fitness_scores)\n        if fitness_scores[min_idx] < self.global_best_score:\n            self.global_best_score = fitness_scores[min_idx].item()\n            self.global_best_position = self.positions[min_idx].clone()\n        \n        # Update velocities\n        r1 = torch.rand_like(self.positions)\n        r2 = torch.rand_like(self.positions)\n        \n        cognitive = self.c1 * r1 * (self.personal_best_positions - self.positions)\n        social = self.c2 * r2 * (self.global_best_position - self.positions)\n        \n        self.velocities = self.w * self.velocities + cognitive + social\n        \n        # Update positions\n        self.positions = self.positions + self.velocities\n        \n        # Apply bounds\n        self.positions = torch.clamp(self.positions, self.bounds[0], self.bounds[1])\n    \n    def optimize(self, healthy_signals, observed_signals, n_iterations=50, verbose=True):\n        \"\"\"\n        Run PSO optimization\n        \n        Args:\n            healthy_signals: Tensor of healthy sensor signals\n            observed_signals: Tensor of observed (damaged) sensor signals\n            n_iterations: Number of PSO iterations\n            verbose: Print progress\n        \n        Returns:\n            Best damage factors found\n        \"\"\"\n        iterator = tqdm(range(n_iterations)) if verbose else range(n_iterations)\n        \n        for iteration in iterator:\n            # Evaluate fitness\n            fitness_scores = self.fitness_function(\n                self.positions, \n                healthy_signals, \n                observed_signals\n            )\n            \n            # Update particles\n            self.update(fitness_scores)\n            \n            # Track history\n            self.history['global_best_scores'].append(self.global_best_score)\n            self.history['mean_scores'].append(fitness_scores.mean().item())\n            self.history['std_scores'].append(fitness_scores.std().item())\n            \n            if verbose and iteration % 10 == 0:\n                iterator.set_description(\n                    f\"Best Fitness: {self.global_best_score:.6f}\"\n                )\n        \n        return self.global_best_position","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n# DATA LOADING AND PROCESSING\n","metadata":{}},{"cell_type":"code","source":"def load_sensor_data(csv_path, sensor_names=['Sensor_24', 'Sensor_31', 'Sensor_32']):\n    \"\"\"Load sensor data from CSV file\"\"\"\n    df = pd.read_csv(csv_path)\n    \n    signals = []\n    for sensor in sensor_names:\n        # Get all columns for this sensor\n        sensor_cols = [col for col in df.columns if sensor in col]\n        if len(sensor_cols) > 0:\n            # Take first acceleration column\n            signal = df[sensor_cols[0]].values\n            signals.append(signal)\n    \n    return np.array(signals)\n\ndef prepare_signals_for_pso(signals, max_length=1000):\n    \"\"\"Convert numpy signals to PyTorch tensors\"\"\"\n    # Truncate or pad to consistent length\n    processed = []\n    for signal in signals:\n        if len(signal) > max_length:\n            signal = signal[:max_length]\n        elif len(signal) < max_length:\n            signal = np.pad(signal, (0, max_length - len(signal)), mode='constant')\n        processed.append(signal)\n    \n    return torch.tensor(np.array(processed), dtype=torch.float32)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EVALUATION AND VISUALIZATION","metadata":{}},{"cell_type":"code","source":"def evaluate_pso_results(predicted_damage, true_damage, threshold=0.9):\n    \"\"\"\n    Evaluate PSO damage localization results\n    \n    Args:\n        predicted_damage: Array of predicted stiffness factors\n        true_damage: Array of true stiffness factors (ground truth)\n        threshold: Values above this are considered healthy\n    \n    Returns:\n        Dictionary with evaluation metrics\n    \"\"\"\n    pred_damaged = predicted_damage < threshold\n    true_damaged = true_damage < threshold\n    \n    # Calculate metrics\n    tp = np.sum(pred_damaged & true_damaged)\n    fp = np.sum(pred_damaged & ~true_damaged)\n    tn = np.sum(~pred_damaged & ~true_damaged)\n    fn = np.sum(~pred_damaged & true_damaged)\n    \n    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n    accuracy = (tp + tn) / (tp + tn + fp + fn)\n    \n    return {\n        'accuracy': accuracy,\n        'precision': precision,\n        'recall': recall,\n        'f1_score': f1,\n        'true_positives': tp,\n        'false_positives': fp,\n        'true_negatives': tn,\n        'false_negatives': fn\n    }\n\ndef plot_pso_results(history, predicted_damage, sensor_names, save_path=None):\n    \"\"\"Plot PSO optimization results\"\"\"\n    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n    \n    # Plot 1: Fitness convergence\n    ax = axes[0]\n    ax.plot(history['global_best_scores'], label='Best Fitness', linewidth=2)\n    ax.plot(history['mean_scores'], label='Mean Fitness', alpha=0.7)\n    ax.fill_between(\n        range(len(history['mean_scores'])),\n        np.array(history['mean_scores']) - np.array(history['std_scores']),\n        np.array(history['mean_scores']) + np.array(history['std_scores']),\n        alpha=0.2\n    )\n    ax.set_xlabel('Iteration')\n    ax.set_ylabel('Fitness (RMS Error)')\n    ax.set_title('PSO Convergence')\n    ax.legend()\n    ax.grid(True, alpha=0.3)\n    \n    # Plot 2: Damage localization\n    ax = axes[1]\n    damage_severity = 1.0 - predicted_damage\n    colors = ['red' if d > 0.1 else 'green' for d in damage_severity]\n    bars = ax.bar(sensor_names, damage_severity, color=colors, alpha=0.7, edgecolor='black')\n    ax.axhline(y=0.1, color='orange', linestyle='--', label='Damage Threshold')\n    ax.set_ylabel('Damage Severity (1 - Stiffness)')\n    ax.set_title('Predicted Damage Localization')\n    ax.legend()\n    ax.grid(True, alpha=0.3, axis='y')\n    \n    # Add value labels on bars\n    for bar, val in zip(bars, damage_severity):\n        height = bar.get_height()\n        ax.text(bar.get_x() + bar.get_width()/2., height,\n                f'{val:.3f}', ha='center', va='bottom')\n    \n    plt.tight_layout()\n    \n    if save_path:\n        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# MAIN PIPELINE","metadata":{}},{"cell_type":"code","source":"def run_pso_on_dataset(healthy_path, damage_paths, n_particles=50, n_iterations=50, \n                       max_samples=10, device='cuda'):\n    \"\"\"\n    Run PSO on complete dataset\n    \n    Args:\n        healthy_path: Path to healthy signal CSV\n        damage_paths: List of paths to damaged signal CSVs\n        n_particles: Number of PSO particles\n        n_iterations: Number of PSO iterations\n        max_samples: Maximum damage cases to process\n        device: 'cuda' or 'cpu'\n    \"\"\"\n    device = torch.device(device if torch.cuda.is_available() else 'cpu')\n    print(f\"Using device: {device}\")\n    \n    sensor_names = ['Sensor_24', 'Sensor_31', 'Sensor_32']\n    \n    # Load healthy signals\n    print(\"Loading healthy signals...\")\n    healthy_signals_np = load_sensor_data(healthy_path, sensor_names)\n    healthy_signals = prepare_signals_for_pso(healthy_signals_np).to(device)\n    \n    print(f\"Healthy signals shape: {healthy_signals.shape}\")\n    \n    results = []\n    \n    # Process damage cases\n    print(f\"\\nProcessing up to {max_samples} damage cases...\")\n    for idx, damage_path in enumerate(damage_paths[:max_samples]):\n        print(f\"\\n{'='*60}\")\n        print(f\"Processing: {damage_path.split('/')[-2]}\")\n        print(f\"{'='*60}\")\n        \n        try:\n            # Load damaged signals\n            damaged_signals_np = load_sensor_data(damage_path, sensor_names)\n            damaged_signals = prepare_signals_for_pso(damaged_signals_np).to(device)\n            \n            # Initialize PSO\n            pso = BridgePSO(\n                n_particles=n_particles,\n                n_elements=len(sensor_names),\n                bounds=(0.1, 1.0),\n                c1=0.5,\n                c2=0.3,\n                w=0.9,\n                device=device\n            )\n            \n            # Run optimization\n            best_damage = pso.optimize(\n                healthy_signals,\n                damaged_signals,\n                n_iterations=n_iterations,\n                verbose=True\n            )\n            \n            # Convert to CPU for analysis\n            predicted_damage = best_damage.cpu().numpy()\n            \n            # Store results\n            result = {\n                'damage_case': damage_path.split('/')[-2],\n                'predicted_stiffness': predicted_damage.tolist(),\n                'damage_severity': (1.0 - predicted_damage).tolist(),\n                'final_fitness': pso.global_best_score,\n                'sensor_names': sensor_names\n            }\n            results.append(result)\n            \n            # Plot results\n            plot_pso_results(\n                pso.history,\n                predicted_damage,\n                sensor_names,\n                save_path=f\"pso_result_{idx+1}.png\"\n            )\n            \n            print(f\"\\nResults for {result['damage_case']}:\")\n            for sensor, stiffness, damage in zip(sensor_names, predicted_damage, 1-predicted_damage):\n                status = \"DAMAGED\" if damage > 0.1 else \"HEALTHY\"\n                print(f\"  {sensor}: Stiffness={stiffness:.3f}, Damage={damage:.3f} [{status}]\")\n            \n        except Exception as e:\n            print(f\"Error processing {damage_path}: {e}\")\n            continue\n    \n    # Save all results\n    results_df = pd.DataFrame([\n        {\n            'damage_case': r['damage_case'],\n            **{f'{sensor}_stiffness': s for sensor, s in zip(sensor_names, r['predicted_stiffness'])},\n            **{f'{sensor}_damage': d for sensor, d in zip(sensor_names, r['damage_severity'])},\n            'final_fitness': r['final_fitness']\n        }\n        for r in results\n    ])\n    \n    results_df.to_csv('pso_damage_localization_results.csv', index=False)\n    print(\"\\n\" + \"=\"*60)\n    print(\"Results saved to: pso_damage_localization_results.csv\")\n    print(\"=\"*60)\n    \n    return results","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Main Execution","metadata":{}},{"cell_type":"code","source":"def main():\n    # Paths (adjust for Kaggle environment)\n    healthy_path = '/kaggle/input/dojo-dataset/complete_simulation_dataset/healthy/2017-11-03.csv'\n    \n    # Collect damage case paths\n    damage_paths = []\n    for i in range(1, 9):\n        pattern = f'/kaggle/input/dojo-dataset/simulation_results (1)/damage_case_{i}_*/2018-07-17_1.csv'\n        damage_paths.extend(glob(pattern))\n    \n    print(f\"Found {len(damage_paths)} damage case files\")\n    \n    # Run PSO\n    results = run_pso_on_dataset(\n        healthy_path=healthy_path,\n        damage_paths=damage_paths,\n        n_particles=50,\n        n_iterations=50,\n        max_samples=10,  # Process first 10 damage cases\n        device='cuda'\n    )\n    \n    print(\"\\n‚úÖ PSO optimization complete!\")\n    print(f\"Processed {len(results)} damage cases\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom glob import glob\nimport warnings\nfrom scipy.fft import fft, fftfreq\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport json\nimport os\nfrom pathlib import Path\n\nwarnings.filterwarnings('ignore')\n\n# ============================================================================\n# GPU-ACCELERATED PSO IMPLEMENTATION\n# ============================================================================\n\nclass BridgePSO:\n    \"\"\"GPU-accelerated Particle Swarm Optimization for damage localization\"\"\"\n    \n    def __init__(self, n_particles=50, n_elements=3, bounds=(0.1, 1.0), \n                 c1=0.5, c2=0.3, w=0.9, device='cuda'):\n        self.n_particles = n_particles\n        self.n_elements = n_elements\n        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')\n        \n        self.c1 = c1\n        self.c2 = c2\n        self.w = w\n        self.bounds = bounds\n        \n        # Initialize particles and velocities\n        self.positions = torch.rand(n_particles, n_elements, device=self.device)\n        self.positions = self.positions * (bounds[1] - bounds[0]) + bounds[0]\n        self.velocities = torch.randn(n_particles, n_elements, device=self.device) * 0.1\n        \n        # Best positions\n        self.personal_best_positions = self.positions.clone()\n        self.personal_best_scores = torch.full((n_particles,), float('inf'), device=self.device)\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n        # History tracking\n        self.history = {\n            'global_best_scores': [],\n            'mean_scores': [],\n            'std_scores': []\n        }\n    \n    def apply_damage_to_signals(self, healthy_signals, damage_factors):\n        \"\"\"Apply damage factors to healthy signals\"\"\"\n        damaged = healthy_signals.clone()\n        for i, factor in enumerate(damage_factors):\n            damaged[i] *= factor\n            noise_level = (1 - factor) * 0.1\n            damaged[i] += torch.randn_like(damaged[i]) * noise_level * damaged[i].std()\n        return damaged\n    \n    def fitness_function(self, particles, healthy_signals, observed_signals):\n        \"\"\"Evaluate fitness for all particles (GPU-accelerated)\"\"\"\n        batch_size = particles.shape[0]\n        fitness_scores = torch.zeros(batch_size, device=self.device)\n        \n        for i in range(batch_size):\n            simulated = self.apply_damage_to_signals(healthy_signals, particles[i])\n            error = torch.sqrt(torch.mean((simulated - observed_signals) ** 2))\n            sparsity_penalty = torch.sum(1.0 - particles[i]) * 0.01\n            fitness_scores[i] = error + sparsity_penalty\n        \n        return fitness_scores\n    \n    def update(self, fitness_scores):\n        \"\"\"Update particle positions and velocities\"\"\"\n        # Update personal bests\n        improved = fitness_scores < self.personal_best_scores\n        self.personal_best_scores[improved] = fitness_scores[improved]\n        self.personal_best_positions[improved] = self.positions[improved].clone()\n        \n        # Update global best\n        min_idx = torch.argmin(fitness_scores)\n        if fitness_scores[min_idx] < self.global_best_score:\n            self.global_best_score = fitness_scores[min_idx].item()\n            self.global_best_position = self.positions[min_idx].clone()\n        \n        # Update velocities and positions\n        r1 = torch.rand_like(self.positions)\n        r2 = torch.rand_like(self.positions)\n        \n        cognitive = self.c1 * r1 * (self.personal_best_positions - self.positions)\n        social = self.c2 * r2 * (self.global_best_position - self.positions)\n        \n        self.velocities = self.w * self.velocities + cognitive + social\n        self.positions = self.positions + self.velocities\n        self.positions = torch.clamp(self.positions, self.bounds[0], self.bounds[1])\n    \n    def optimize(self, healthy_signals, observed_signals, n_iterations=50, verbose=True):\n        \"\"\"Run PSO optimization\"\"\"\n        iterator = tqdm(range(n_iterations), disable=not verbose)\n        \n        for iteration in iterator:\n            fitness_scores = self.fitness_function(self.positions, healthy_signals, observed_signals)\n            self.update(fitness_scores)\n            \n            self.history['global_best_scores'].append(self.global_best_score)\n            self.history['mean_scores'].append(fitness_scores.mean().item())\n            self.history['std_scores'].append(fitness_scores.std().item())\n            \n            if verbose and iteration % 10 == 0:\n                iterator.set_description(f\"Best Fitness: {self.global_best_score:.6f}\")\n        \n        return self.global_best_position\n\n# ============================================================================\n# DATA LOADING\n# ============================================================================\n\ndef load_sensor_data(csv_path, sensor_names=['Sensor_24', 'Sensor_31', 'Sensor_32']):\n    \"\"\"Load sensor data from CSV file\"\"\"\n    try:\n        df = pd.read_csv(csv_path)\n        signals = []\n        for sensor in sensor_names:\n            sensor_cols = [col for col in df.columns if sensor in col]\n            if len(sensor_cols) > 0:\n                signals.append(df[sensor_cols[0]].values)\n        \n        return np.array(signals) if len(signals) == len(sensor_names) else None\n    except Exception as e:\n        return None\n\ndef create_synthetic_damage(healthy_signals, damage_pattern):\n    \"\"\"Create synthetic damage scenarios\"\"\"\n    device = healthy_signals.device\n    n_sensors = healthy_signals.shape[0]\n    \n    true_damage_factors = torch.ones(n_sensors, device=device)\n    for sensor_idx in damage_pattern['sensors']:\n        if sensor_idx < n_sensors:\n            true_damage_factors[sensor_idx] = damage_pattern['severity']\n    \n    damaged_signals = healthy_signals.clone()\n    for i, factor in enumerate(true_damage_factors):\n        damaged_signals[i] *= factor\n        noise_level = (1 - factor) * 0.08\n        damaged_signals[i] += torch.randn_like(damaged_signals[i]) * noise_level * damaged_signals[i].std()\n    \n    return damaged_signals, true_damage_factors\n\n# ============================================================================\n# EVALUATION\n# ============================================================================\n\ndef evaluate_pso_results(predicted_damage, true_damage, threshold=0.9):\n    \"\"\"Evaluate PSO damage localization results\"\"\"\n    pred_damaged = predicted_damage < threshold\n    true_damaged = true_damage < threshold\n    \n    tp = np.sum(pred_damaged & true_damaged)\n    fp = np.sum(pred_damaged & ~true_damaged)\n    tn = np.sum(~pred_damaged & ~true_damaged)\n    fn = np.sum(~pred_damaged & true_damaged)\n    \n    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n    accuracy = (tp + tn) / (tp + tn + fp + fn)\n    \n    return {\n        'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1_score': f1,\n        'true_positives': tp, 'false_positives': fp, 'true_negatives': tn, 'false_negatives': fn\n    }\n\n# ============================================================================\n# VISUALIZATION\n# ============================================================================\n\ndef plot_pso_results(history, predicted_damage, true_damage, sensor_names, metrics, case_name, save_path):\n    \"\"\"Plot comprehensive PSO optimization results\"\"\"\n    fig = plt.figure(figsize=(18, 10))\n    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n    \n    # Plot 1: Fitness convergence\n    ax1 = fig.add_subplot(gs[0, :2])\n    ax1.plot(history['global_best_scores'], label='Best Fitness', linewidth=2.5, color='#2E86AB')\n    ax1.plot(history['mean_scores'], label='Mean Fitness', alpha=0.7, linewidth=2, color='#A23B72')\n    ax1.fill_between(range(len(history['mean_scores'])),\n                     np.array(history['mean_scores']) - np.array(history['std_scores']),\n                     np.array(history['mean_scores']) + np.array(history['std_scores']),\n                     alpha=0.2, color='#A23B72')\n    ax1.set_xlabel('Iteration', fontsize=12, fontweight='bold')\n    ax1.set_ylabel('Fitness (RMS Error)', fontsize=12, fontweight='bold')\n    ax1.set_title(f'PSO Convergence - {case_name}', fontsize=14, fontweight='bold')\n    ax1.legend(fontsize=10)\n    ax1.grid(True, alpha=0.3)\n    \n    # Plot 2: Performance Metrics\n    ax2 = fig.add_subplot(gs[0, 2])\n    metric_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n    metric_values = [metrics['accuracy'], metrics['precision'], metrics['recall'], metrics['f1_score']]\n    colors_metrics = ['#06A77D', '#F18F01', '#C73E1D', '#6A4C93']\n    bars = ax2.barh(metric_names, metric_values, color=colors_metrics, alpha=0.8, edgecolor='black')\n    ax2.set_xlim(0, 1)\n    ax2.set_xlabel('Score', fontsize=11, fontweight='bold')\n    ax2.set_title('Performance Metrics', fontsize=12, fontweight='bold')\n    ax2.grid(True, alpha=0.3, axis='x')\n    for bar, val in zip(bars, metric_values):\n        ax2.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height()/2.,\n                f'{val:.3f}', ha='left', va='center', fontweight='bold')\n    \n    # Plot 3: Stiffness Comparison\n    ax3 = fig.add_subplot(gs[1, :2])\n    x = np.arange(len(sensor_names))\n    width = 0.35\n    pred_stiffness = predicted_damage\n    true_stiffness = true_damage.cpu().numpy() if isinstance(true_damage, torch.Tensor) else true_damage\n    \n    bars1 = ax3.bar(x - width/2, true_stiffness, width, label='True Stiffness', \n                    color='#06A77D', alpha=0.8, edgecolor='black')\n    bars2 = ax3.bar(x + width/2, pred_stiffness, width, label='Predicted Stiffness',\n                    color='#F18F01', alpha=0.8, edgecolor='black')\n    ax3.set_ylabel('Stiffness Factor', fontsize=12, fontweight='bold')\n    ax3.set_title('Stiffness Comparison: True vs Predicted', fontsize=13, fontweight='bold')\n    ax3.set_xticks(x)\n    ax3.set_xticklabels(sensor_names, rotation=45, ha='right')\n    ax3.legend(fontsize=10)\n    ax3.grid(True, alpha=0.3, axis='y')\n    ax3.set_ylim(0, 1.1)\n    \n    for bars in [bars1, bars2]:\n        for bar in bars:\n            height = bar.get_height()\n            ax3.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n                    f'{height:.2f}', ha='center', va='bottom', fontsize=9)\n    \n    # Plot 4: Damage Severity\n    ax4 = fig.add_subplot(gs[1, 2])\n    true_damage_sev = 1.0 - true_stiffness\n    pred_damage_sev = 1.0 - pred_stiffness\n    \n    bars1 = ax4.bar(x - width/2, true_damage_sev, width, label='True Damage',\n                    color='#C73E1D', alpha=0.8, edgecolor='black')\n    bars2 = ax4.bar(x + width/2, pred_damage_sev, width, label='Predicted Damage',\n                    color='#6A4C93', alpha=0.8, edgecolor='black')\n    ax4.axhline(y=0.1, color='orange', linestyle='--', linewidth=2, label='Damage Threshold')\n    ax4.set_ylabel('Damage Severity', fontsize=11, fontweight='bold')\n    ax4.set_title('Damage Severity', fontsize=12, fontweight='bold')\n    ax4.set_xticks(x)\n    ax4.set_xticklabels(sensor_names, rotation=45, ha='right')\n    ax4.legend(fontsize=9)\n    ax4.grid(True, alpha=0.3, axis='y')\n    \n    # Plot 5: Error Analysis\n    ax5 = fig.add_subplot(gs[2, :])\n    stiffness_error = np.abs(pred_stiffness - true_stiffness)\n    damage_error = np.abs(pred_damage_sev - true_damage_sev)\n    \n    bars1 = ax5.bar(x - width/2, stiffness_error, width, label='Stiffness Error',\n                    color='#2E86AB', alpha=0.8, edgecolor='black')\n    bars2 = ax5.bar(x + width/2, damage_error, width, label='Damage Severity Error',\n                    color='#A23B72', alpha=0.8, edgecolor='black')\n    ax5.set_ylabel('Absolute Error', fontsize=12, fontweight='bold')\n    ax5.set_xlabel('Sensors', fontsize=12, fontweight='bold')\n    ax5.set_title('Prediction Error Analysis', fontsize=13, fontweight='bold')\n    ax5.set_xticks(x)\n    ax5.set_xticklabels(sensor_names)\n    ax5.legend(fontsize=10)\n    ax5.grid(True, alpha=0.3, axis='y')\n    \n    for bars in [bars1, bars2]:\n        for bar in bars:\n            height = bar.get_height()\n            if height > 0.01:\n                ax5.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n                        f'{height:.3f}', ha='center', va='bottom', fontsize=8)\n    \n    plt.suptitle(f'PSO Damage Localization Results - {case_name}', \n                fontsize=16, fontweight='bold', y=0.995)\n    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')\n    plt.close()\n    print(f\"   ‚úÖ Graph saved: {save_path}\")\n\ndef plot_overall_performance(all_metrics, scenarios, save_path):\n    \"\"\"Plot overall performance across all scenarios\"\"\"\n    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n    scenario_names = [s['name'] for s in scenarios]\n    \n    # Plot 1: Accuracy across scenarios\n    ax = axes[0, 0]\n    accuracies = [m['accuracy'] for m in all_metrics]\n    colors = ['#06A77D' if acc > 0.8 else '#F18F01' if acc > 0.6 else '#C73E1D' for acc in accuracies]\n    ax.bar(range(len(accuracies)), accuracies, color=colors, alpha=0.8, edgecolor='black')\n    ax.set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n    ax.set_title('Accuracy Across Scenarios', fontsize=13, fontweight='bold')\n    ax.set_xticks(range(len(scenario_names)))\n    ax.set_xticklabels(scenario_names, rotation=45, ha='right', fontsize=8)\n    ax.axhline(y=0.8, color='green', linestyle='--', alpha=0.5, label='Good (0.8)')\n    ax.axhline(y=0.6, color='orange', linestyle='--', alpha=0.5, label='Fair (0.6)')\n    ax.set_ylim(0, 1.1)\n    ax.legend()\n    ax.grid(True, alpha=0.3, axis='y')\n    \n    # Plot 2: All metrics comparison\n    ax = axes[0, 1]\n    x = np.arange(len(all_metrics))\n    width = 0.2\n    precisions = [m['precision'] for m in all_metrics]\n    recalls = [m['recall'] for m in all_metrics]\n    f1_scores = [m['f1_score'] for m in all_metrics]\n    \n    ax.bar(x - width, accuracies, width, label='Accuracy', color='#06A77D', alpha=0.8)\n    ax.bar(x, precisions, width, label='Precision', color='#F18F01', alpha=0.8)\n    ax.bar(x + width, recalls, width, label='Recall', color='#C73E1D', alpha=0.8)\n    ax.bar(x + 2*width, f1_scores, width, label='F1-Score', color='#6A4C93', alpha=0.8)\n    ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n    ax.set_title('All Metrics Comparison', fontsize=13, fontweight='bold')\n    ax.set_xticks(x + width/2)\n    ax.set_xticklabels(range(1, len(all_metrics)+1))\n    ax.set_xlabel('Scenario Number', fontsize=11, fontweight='bold')\n    ax.legend()\n    ax.grid(True, alpha=0.3, axis='y')\n    ax.set_ylim(0, 1.1)\n    \n    # Plot 3: Confusion Matrix\n    ax = axes[1, 0]\n    total_tp = sum(m['true_positives'] for m in all_metrics)\n    total_fp = sum(m['false_positives'] for m in all_metrics)\n    total_tn = sum(m['true_negatives'] for m in all_metrics)\n    total_fn = sum(m['false_negatives'] for m in all_metrics)\n    \n    confusion = np.array([[total_tn, total_fp], [total_fn, total_tp]])\n    im = ax.imshow(confusion, cmap='Blues', alpha=0.8)\n    ax.set_xticks([0, 1])\n    ax.set_yticks([0, 1])\n    ax.set_xticklabels(['Predicted Healthy', 'Predicted Damaged'], fontsize=10)\n    ax.set_yticklabels(['True Healthy', 'True Damaged'], fontsize=10)\n    ax.set_title('Cumulative Confusion Matrix', fontsize=13, fontweight='bold')\n    \n    for i in range(2):\n        for j in range(2):\n            ax.text(j, i, confusion[i, j], ha=\"center\", va=\"center\", \n                   color=\"black\", fontsize=20, fontweight='bold')\n    plt.colorbar(im, ax=ax)\n    \n    # Plot 4: Distribution\n    ax = axes[1, 1]\n    metrics_data = [accuracies, precisions, recalls, f1_scores]\n    positions = [1, 2, 3, 4]\n    ax.boxplot(metrics_data, positions=positions, widths=0.6, patch_artist=True,\n               boxprops=dict(facecolor='lightblue', alpha=0.7),\n               medianprops=dict(color='red', linewidth=2))\n    ax.set_xticklabels(['Accuracy', 'Precision', 'Recall', 'F1-Score'], fontsize=11)\n    ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n    ax.set_title('Performance Metrics Distribution', fontsize=13, fontweight='bold')\n    ax.grid(True, alpha=0.3, axis='y')\n    ax.set_ylim(0, 1.1)\n    \n    means = [np.mean(data) for data in metrics_data]\n    ax.plot(positions, means, 'D', color='green', markersize=10, label='Mean', zorder=3)\n    ax.legend()\n    \n    plt.suptitle('PSO Damage Localization - Overall Performance Analysis', \n                fontsize=16, fontweight='bold', y=0.995)\n    plt.tight_layout()\n    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')\n    plt.close()\n    print(f\"   ‚úÖ Overall performance graph: {save_path}\")\n\n# ============================================================================\n# MAIN PIPELINE\n# ============================================================================\n\ndef run_pso_simulation(healthy_paths=None, healthy_signals_tensor=None, n_particles=50, \n                      n_iterations=50, n_damage_scenarios=15, device='cuda', output_dir='pso_results'):\n    \"\"\"Run PSO simulation on multiple healthy datasets\"\"\"\n    os.makedirs(output_dir, exist_ok=True)\n    device = torch.device(device if torch.cuda.is_available() else 'cpu')\n    print(f\"üöÄ Using device: {device}\")\n    \n    sensor_names = ['Sensor_24', 'Sensor_31', 'Sensor_32']\n    max_length = 1000\n    \n    # Check if pre-computed tensor is provided\n    if healthy_signals_tensor is not None:\n        healthy_signals = healthy_signals_tensor.to(device)\n        print(f\"\\nüìä Using pre-computed healthy signals tensor\")\n        print(f\"   üìè Healthy signals shape: {healthy_signals.shape}\")\n    else:\n        # Load and normalize all healthy signals from files\n        print(f\"\\nüìä Loading {len(healthy_paths)} healthy datasets...\")\n        healthy_signals_list = []\n        \n        for path in tqdm(healthy_paths):\n            signals = load_sensor_data(path, sensor_names)\n            if signals is not None:\n                normalized_signals = []\n                for signal in signals:\n                    if len(signal) > max_length:\n                        signal = signal[:max_length]\n                    elif len(signal) < max_length:\n                        signal = np.pad(signal, (0, max_length - len(signal)), mode='constant')\n                    normalized_signals.append(signal)\n                healthy_signals_list.append(np.array(normalized_signals))\n        \n        print(f\"   ‚úÖ Successfully loaded {len(healthy_signals_list)} healthy datasets\")\n        \n        if len(healthy_signals_list) == 0:\n            raise ValueError(\"No healthy datasets loaded! Please provide valid CSV files or a healthy_signals_tensor.\")\n        \n        # Calculate ensemble baseline\n        healthy_signals_array = np.array(healthy_signals_list)\n        healthy_baseline = np.mean(healthy_signals_array, axis=0)\n        healthy_signals = torch.tensor(healthy_baseline, dtype=torch.float32).to(device)\n        print(f\"   üìè Healthy signals shape: {healthy_signals.shape}\")\n    \n    # Define damage scenarios\n    damage_scenarios = [\n        {'name': 'Single_Sensor24_Severe', 'sensors': [0], 'severity': 0.3},\n        {'name': 'Single_Sensor24_Moderate', 'sensors': [0], 'severity': 0.6},\n        {'name': 'Single_Sensor31_Severe', 'sensors': [1], 'severity': 0.3},\n        {'name': 'Single_Sensor31_Moderate', 'sensors': [1], 'severity': 0.6},\n        {'name': 'Single_Sensor32_Severe', 'sensors': [2], 'severity': 0.3},\n        {'name': 'Single_Sensor32_Moderate', 'sensors': [2], 'severity': 0.6},\n        {'name': 'Double_S24_S31_Severe', 'sensors': [0, 1], 'severity': 0.4},\n        {'name': 'Double_S24_S31_Moderate', 'sensors': [0, 1], 'severity': 0.7},\n        {'name': 'Double_S24_S32_Severe', 'sensors': [0, 2], 'severity': 0.4},\n        {'name': 'Double_S31_S32_Moderate', 'sensors': [1, 2], 'severity': 0.7},\n        {'name': 'Triple_All_Mild', 'sensors': [0, 1, 2], 'severity': 0.8},\n        {'name': 'Triple_All_Moderate', 'sensors': [0, 1, 2], 'severity': 0.6},\n        {'name': 'Triple_All_Severe', 'sensors': [0, 1, 2], 'severity': 0.4},\n        {'name': 'Single_Sensor24_Mild', 'sensors': [0], 'severity': 0.85},\n        {'name': 'Single_Sensor32_Mild', 'sensors': [2], 'severity': 0.85},\n    ]\n    \n    results = []\n    all_metrics = []\n    \n    print(f\"\\nüî¨ Running PSO on {len(damage_scenarios[:n_damage_scenarios])} damage scenarios...\\n\")\n    \n    for idx, scenario in enumerate(damage_scenarios[:n_damage_scenarios]):\n        print(f\"{'='*70}\")\n        print(f\"üîß Scenario {idx+1}/{min(n_damage_scenarios, len(damage_scenarios))}: {scenario['name']}\")\n        print(f\"{'='*70}\")\n        \n        try:\n            damaged_signals, true_damage = create_synthetic_damage(healthy_signals, scenario)\n            print(f\"   üéØ True damage: {(1 - true_damage.cpu().numpy()).round(3).tolist()}\")\n            \n            pso = BridgePSO(n_particles=n_particles, n_elements=len(sensor_names),\n                          bounds=(0.1, 1.0), c1=0.5, c2=0.3, w=0.9, device=device)\n            \n            best_damage = pso.optimize(healthy_signals, damaged_signals, n_iterations, verbose=True)\n            predicted_damage = best_damage.cpu().numpy()\n            metrics = evaluate_pso_results(predicted_damage, true_damage.cpu().numpy())\n            \n            print(f\"\\n   üìä Metrics: Acc={metrics['accuracy']:.3f}, Prec={metrics['precision']:.3f}, \"\n                  f\"Recall={metrics['recall']:.3f}, F1={metrics['f1_score']:.3f}\")\n            \n            result = {\n                'scenario': scenario['name'],\n                'true_damage_sensors': scenario['sensors'],\n                'true_severity': scenario['severity'],\n                'predicted_stiffness': predicted_damage.tolist(),\n                'predicted_damage_severity': (1.0 - predicted_damage).tolist(),\n                'final_fitness': pso.global_best_score,\n                'sensor_names': sensor_names,\n                **metrics\n            }\n            results.append(result)\n            all_metrics.append(metrics)\n            \n            save_path = os.path.join(output_dir, f\"pso_scenario_{idx+1:02d}_{scenario['name']}.png\")\n            plot_pso_results(pso.history, predicted_damage, true_damage, sensor_names, \n                           metrics, scenario['name'], save_path)\n            \n            print(f\"\\n   ‚ú® Predictions:\")\n            for sensor, pred_stiff, pred_damage in zip(sensor_names, predicted_damage, 1-predicted_damage):\n                status = \"üî¥ DAMAGED\" if pred_damage > 0.1 else \"üü¢ HEALTHY\"\n                print(f\"      {sensor}: Stiffness={pred_stiff:.3f}, Damage={pred_damage:.3f} [{status}]\")\n            \n        except Exception as e:\n            print(f\"   ‚ùå Error: {e}\")\n            continue\n    \n    # Save results\n    print(f\"\\n{'='*70}\")\n    print(\"üíæ Saving results...\")\n    print(f\"{'='*70}\")\n    \n    results_df = pd.DataFrame([{\n        'scenario': r['scenario'],\n        'true_damage_sensors': str(r['true_damage_sensors']),\n        'true_severity': r['true_severity'],\n        **{f'{sensor}_pred_stiffness': s for sensor, s in zip(sensor_names, r['predicted_stiffness'])},\n        **{f'{sensor}_pred_damage': d for sensor, d in zip(sensor_names, r['predicted_damage_severity'])},\n        'final_fitness': r['final_fitness'],\n        'accuracy': r['accuracy'],\n        'precision': r['precision'],\n        'recall': r['recall'],\n        'f1_score': r['f1_score']\n    } for r in results])\n    \n    csv_path = os.path.join(output_dir, 'pso_damage_localization_results.csv')\n    results_df.to_csv(csv_path, index=False)\n    print(f\"   ‚úÖ Results CSV: {csv_path}\")\n    \n    summary_stats = {\n        'total_scenarios': len(results),\n        'mean_accuracy': np.mean([m['accuracy'] for m in all_metrics]),\n        'mean_precision': np.mean([m['precision'] for m in all_metrics]),\n        'mean_recall': np.mean([m['recall'] for m in all_metrics]),\n        'mean_f1_score': np.mean([m['f1_score'] for m in all_metrics]),\n        'std_accuracy': np.std([m['accuracy'] for m in all_metrics]),\n        'std_precision': np.std([m['precision'] for m in all_metrics]),\n        'std_recall': np.std([m['recall'] for m in all_metrics]),\n        'std_f1_score': np.std([m['f1_score'] for m in all_metrics])\n    }\n    \n    json_path = os.path.join(output_dir, 'pso_summary_statistics.json')\n    with open(json_path, 'w') as f:\n        json.dump(summary_stats, f, indent=4)\n    print(f\"   ‚úÖ Summary JSON: {json_path}\")\n    \n    plot_overall_performance(all_metrics, damage_scenarios[:n_damage_scenarios], \n                           os.path.join(output_dir, 'pso_overall_performance.png'))\n    \n    print(f\"\\n{'='*70}\")\n    print(\"‚úÖ PSO SIMULATION COMPLETE!\")\n    print(f\"{'='*70}\")\n    print(f\"\\nüìà Overall Performance:\")\n    print(f\"   Mean Accuracy:  {summary_stats['mean_accuracy']:.4f} ¬± {summary_stats['std_accuracy']:.4f}\")\n    print(f\"   Mean Precision: {summary_stats['mean_precision']:.4f} ¬± {summary_stats['std_precision']:.4f}\")\n    print(f\"   Mean Recall:    {summary_stats['mean_recall']:.4f} ¬± {summary_stats['std_recall']:.4f}\")\n    print(f\"   Mean F1-Score:  {summary_stats['mean_f1_score']:.4f} ¬± {summary_stats['std_f1_score']:.4f}\")\n    \n    return results, summary_stats\n\n# ============================================================================\n# EXECUTION\n# ============================================================================\n\nif __name__ == \"__main__\":\n    # Example usage\n    print(\"=\"*70)\n    print(\"  PSO-BASED BRIDGE DAMAGE LOCALIZATION SYSTEM\")\n    print(\"=\"*70)\n    \n    # Find all healthy CSV files\n    healthy_csv_pattern = \"healthy_*.csv\"  # Modify this pattern as needed\n    healthy_paths = glob(healthy_csv_pattern)\n    \n    if len(healthy_paths) == 0:\n        print(\"\\n‚ö†Ô∏è  No healthy CSV files found!\")\n        print(\"   Please place healthy sensor data CSV files in the current directory\")\n        print(\"   Expected pattern: healthy_*.csv\")\n        print(\"\\n   Creating synthetic demo instead...\")\n        \n        # Create synthetic demo data\n        n_sensors = 3\n        n_samples = 1000\n        synthetic_signals = []\n        \n        for i in range(5):  # 5 synthetic healthy datasets\n            sensor_data = []\n            for s in range(n_sensors):\n                # Generate synthetic vibration signals\n                t = np.linspace(0, 10, n_samples)\n                freq = 2 + s * 0.5\n                signal = np.sin(2 * np.pi * freq * t) + np.random.normal(0, 0.1, n_samples)\n                sensor_data.append(signal)\n            synthetic_signals.append(np.array(sensor_data))\n        \n        # Convert to tensor\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        healthy_baseline = np.mean(synthetic_signals, axis=0)\n        healthy_signals = torch.tensor(healthy_baseline, dtype=torch.float32).to(device)\n        \n        print(f\"\\n‚úÖ Created synthetic healthy signals: {healthy_signals.shape}\")\n        print(f\"üöÄ Running PSO with synthetic data...\\n\")\n        \n        # Run simulation with synthetic data\n        results, summary = run_pso_simulation(\n            healthy_signals_tensor=healthy_signals,  # Pass the pre-computed tensor\n            n_particles=30,\n            n_iterations=40,\n            n_damage_scenarios=10,\n            device='cuda',\n            output_dir='pso_results_synthetic'\n        )\n        \n    else:\n        print(f\"\\n‚úÖ Found {len(healthy_paths)} healthy CSV files\")\n        print(\"   Files:\", [Path(p).name for p in healthy_paths[:5]], \"...\" if len(healthy_paths) > 5 else \"\")\n        \n        # Run simulation with real data\n        results, summary = run_pso_simulation(\n            healthy_paths=healthy_paths,\n            n_particles=50,\n            n_iterations=50,\n            n_damage_scenarios=15,\n            device='cuda',\n            output_dir='pso_results'\n        )\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"  SIMULATION COMPLETED SUCCESSFULLY!\")\n    print(\"=\"*70)\n    print(\"\\nüìÅ Check the output directory for:\")\n    print(\"   ‚Ä¢ Individual scenario plots\")\n    print(\"   ‚Ä¢ Overall performance analysis\")\n    print(\"   ‚Ä¢ Results CSV file\")\n    print(\"   ‚Ä¢ Summary statistics JSON\")\n    print(\"\\nüéâ All done!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom glob import glob\nimport warnings\nfrom scipy.fft import fft, fftfreq\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport json\nimport os\nfrom pathlib import Path\n\nwarnings.filterwarnings('ignore')\n\n# ============================================================================\n# GPU-ACCELERATED PSO IMPLEMENTATION\n# ============================================================================\n\nclass BridgePSO:\n    \"\"\"GPU-accelerated Particle Swarm Optimization for damage localization\"\"\"\n    \n    def __init__(self, n_particles=50, n_elements=3, bounds=(0.1, 1.0), \n                 c1=0.5, c2=0.3, w=0.9, device='cuda'):\n        self.n_particles = n_particles\n        self.n_elements = n_elements\n        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')\n        \n        self.c1 = c1\n        self.c2 = c2\n        self.w = w\n        self.bounds = bounds\n        \n        # Initialize particles and velocities\n        self.positions = torch.rand(n_particles, n_elements, device=self.device)\n        self.positions = self.positions * (bounds[1] - bounds[0]) + bounds[0]\n        self.velocities = torch.randn(n_particles, n_elements, device=self.device) * 0.1\n        \n        # Best positions\n        self.personal_best_positions = self.positions.clone()\n        self.personal_best_scores = torch.full((n_particles,), float('inf'), device=self.device)\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        \n        # History tracking\n        self.history = {\n            'global_best_scores': [],\n            'mean_scores': [],\n            'std_scores': []\n        }\n    \n    def apply_damage_to_signals(self, healthy_signals, damage_factors):\n        \"\"\"Apply damage factors to healthy signals\"\"\"\n        damaged = healthy_signals.clone()\n        for i, factor in enumerate(damage_factors):\n            damaged[i] *= factor\n            noise_level = (1 - factor) * 0.1\n            damaged[i] += torch.randn_like(damaged[i]) * noise_level * damaged[i].std()\n        return damaged\n    \n    def fitness_function(self, particles, healthy_signals, observed_signals):\n        \"\"\"Evaluate fitness for all particles (GPU-accelerated)\"\"\"\n        batch_size = particles.shape[0]\n        fitness_scores = torch.zeros(batch_size, device=self.device)\n        \n        for i in range(batch_size):\n            simulated = self.apply_damage_to_signals(healthy_signals, particles[i])\n            error = torch.sqrt(torch.mean((simulated - observed_signals) ** 2))\n            sparsity_penalty = torch.sum(1.0 - particles[i]) * 0.01\n            fitness_scores[i] = error + sparsity_penalty\n        \n        return fitness_scores\n    \n    def update(self, fitness_scores):\n        \"\"\"Update particle positions and velocities\"\"\"\n        # Update personal bests\n        improved = fitness_scores < self.personal_best_scores\n        self.personal_best_scores[improved] = fitness_scores[improved]\n        self.personal_best_positions[improved] = self.positions[improved].clone()\n        \n        # Update global best\n        min_idx = torch.argmin(fitness_scores)\n        if fitness_scores[min_idx] < self.global_best_score:\n            self.global_best_score = fitness_scores[min_idx].item()\n            self.global_best_position = self.positions[min_idx].clone()\n        \n        # Update velocities and positions\n        r1 = torch.rand_like(self.positions)\n        r2 = torch.rand_like(self.positions)\n        \n        cognitive = self.c1 * r1 * (self.personal_best_positions - self.positions)\n        social = self.c2 * r2 * (self.global_best_position - self.positions)\n        \n        self.velocities = self.w * self.velocities + cognitive + social\n        self.positions = self.positions + self.velocities\n        self.positions = torch.clamp(self.positions, self.bounds[0], self.bounds[1])\n    \n    def optimize(self, healthy_signals, observed_signals, n_iterations=50, verbose=True):\n        \"\"\"Run PSO optimization\"\"\"\n        iterator = tqdm(range(n_iterations), disable=not verbose)\n        \n        for iteration in iterator:\n            fitness_scores = self.fitness_function(self.positions, healthy_signals, observed_signals)\n            self.update(fitness_scores)\n            \n            self.history['global_best_scores'].append(self.global_best_score)\n            self.history['mean_scores'].append(fitness_scores.mean().item())\n            self.history['std_scores'].append(fitness_scores.std().item())\n            \n            if verbose and iteration % 10 == 0:\n                iterator.set_description(f\"Best Fitness: {self.global_best_score:.6f}\")\n        \n        return self.global_best_position\n\n# ============================================================================\n# DATA LOADING\n# ============================================================================\n\ndef load_sensor_data(csv_path, sensor_names=['Sensor_24', 'Sensor_31', 'Sensor_32']):\n    \"\"\"Load sensor data from CSV file\"\"\"\n    try:\n        df = pd.read_csv(csv_path)\n        signals = []\n        for sensor in sensor_names:\n            sensor_cols = [col for col in df.columns if sensor in col]\n            if len(sensor_cols) > 0:\n                signals.append(df[sensor_cols[0]].values)\n        \n        return np.array(signals) if len(signals) == len(sensor_names) else None\n    except Exception as e:\n        return None\n\ndef create_synthetic_damage(healthy_signals, damage_pattern):\n    \"\"\"Create synthetic damage scenarios\"\"\"\n    device = healthy_signals.device\n    n_sensors = healthy_signals.shape[0]\n    \n    true_damage_factors = torch.ones(n_sensors, device=device)\n    for sensor_idx in damage_pattern['sensors']:\n        if sensor_idx < n_sensors:\n            true_damage_factors[sensor_idx] = damage_pattern['severity']\n    \n    damaged_signals = healthy_signals.clone()\n    for i, factor in enumerate(true_damage_factors):\n        damaged_signals[i] *= factor\n        noise_level = (1 - factor) * 0.08\n        damaged_signals[i] += torch.randn_like(damaged_signals[i]) * noise_level * damaged_signals[i].std()\n    \n    return damaged_signals, true_damage_factors\n\n# ============================================================================\n# EVALUATION\n# ============================================================================\n\ndef evaluate_pso_results(predicted_damage, true_damage, threshold=0.9):\n    \"\"\"Evaluate PSO damage localization results\"\"\"\n    pred_damaged = predicted_damage < threshold\n    true_damaged = true_damage < threshold\n    \n    tp = np.sum(pred_damaged & true_damaged)\n    fp = np.sum(pred_damaged & ~true_damaged)\n    tn = np.sum(~pred_damaged & ~true_damaged)\n    fn = np.sum(~pred_damaged & true_damaged)\n    \n    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n    accuracy = (tp + tn) / (tp + tn + fp + fn)\n    \n    return {\n        'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1_score': f1,\n        'true_positives': tp, 'false_positives': fp, 'true_negatives': tn, 'false_negatives': fn\n    }\n\n# ============================================================================\n# VISUALIZATION\n# ============================================================================\n\ndef plot_pso_results(history, predicted_damage, true_damage, sensor_names, metrics, case_name, save_path):\n    \"\"\"Plot comprehensive PSO optimization results\"\"\"\n    fig = plt.figure(figsize=(18, 10))\n    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n    \n    # Plot 1: Fitness convergence\n    ax1 = fig.add_subplot(gs[0, :2])\n    ax1.plot(history['global_best_scores'], label='Best Fitness', linewidth=2.5, color='#2E86AB')\n    ax1.plot(history['mean_scores'], label='Mean Fitness', alpha=0.7, linewidth=2, color='#A23B72')\n    ax1.fill_between(range(len(history['mean_scores'])),\n                     np.array(history['mean_scores']) - np.array(history['std_scores']),\n                     np.array(history['mean_scores']) + np.array(history['std_scores']),\n                     alpha=0.2, color='#A23B72')\n    ax1.set_xlabel('Iteration', fontsize=12, fontweight='bold')\n    ax1.set_ylabel('Fitness (RMS Error)', fontsize=12, fontweight='bold')\n    ax1.set_title(f'PSO Convergence - {case_name}', fontsize=14, fontweight='bold')\n    ax1.legend(fontsize=10)\n    ax1.grid(True, alpha=0.3)\n    \n    # Plot 2: Performance Metrics\n    ax2 = fig.add_subplot(gs[0, 2])\n    metric_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n    metric_values = [metrics['accuracy'], metrics['precision'], metrics['recall'], metrics['f1_score']]\n    colors_metrics = ['#06A77D', '#F18F01', '#C73E1D', '#6A4C93']\n    bars = ax2.barh(metric_names, metric_values, color=colors_metrics, alpha=0.8, edgecolor='black')\n    ax2.set_xlim(0, 1)\n    ax2.set_xlabel('Score', fontsize=11, fontweight='bold')\n    ax2.set_title('Performance Metrics', fontsize=12, fontweight='bold')\n    ax2.grid(True, alpha=0.3, axis='x')\n    for bar, val in zip(bars, metric_values):\n        ax2.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height()/2.,\n                f'{val:.3f}', ha='left', va='center', fontweight='bold')\n    \n    # Plot 3: Stiffness Comparison\n    ax3 = fig.add_subplot(gs[1, :2])\n    x = np.arange(len(sensor_names))\n    width = 0.35\n    pred_stiffness = predicted_damage\n    true_stiffness = true_damage.cpu().numpy() if isinstance(true_damage, torch.Tensor) else true_damage\n    \n    bars1 = ax3.bar(x - width/2, true_stiffness, width, label='True Stiffness', \n                    color='#06A77D', alpha=0.8, edgecolor='black')\n    bars2 = ax3.bar(x + width/2, pred_stiffness, width, label='Predicted Stiffness',\n                    color='#F18F01', alpha=0.8, edgecolor='black')\n    ax3.set_ylabel('Stiffness Factor', fontsize=12, fontweight='bold')\n    ax3.set_title('Stiffness Comparison: True vs Predicted', fontsize=13, fontweight='bold')\n    ax3.set_xticks(x)\n    ax3.set_xticklabels(sensor_names, rotation=45, ha='right')\n    ax3.legend(fontsize=10)\n    ax3.grid(True, alpha=0.3, axis='y')\n    ax3.set_ylim(0, 1.1)\n    \n    for bars in [bars1, bars2]:\n        for bar in bars:\n            height = bar.get_height()\n            ax3.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n                    f'{height:.2f}', ha='center', va='bottom', fontsize=9)\n    \n    # Plot 4: Damage Severity\n    ax4 = fig.add_subplot(gs[1, 2])\n    true_damage_sev = 1.0 - true_stiffness\n    pred_damage_sev = 1.0 - pred_stiffness\n    \n    bars1 = ax4.bar(x - width/2, true_damage_sev, width, label='True Damage',\n                    color='#C73E1D', alpha=0.8, edgecolor='black')\n    bars2 = ax4.bar(x + width/2, pred_damage_sev, width, label='Predicted Damage',\n                    color='#6A4C93', alpha=0.8, edgecolor='black')\n    ax4.axhline(y=0.1, color='orange', linestyle='--', linewidth=2, label='Damage Threshold')\n    ax4.set_ylabel('Damage Severity', fontsize=11, fontweight='bold')\n    ax4.set_title('Damage Severity', fontsize=12, fontweight='bold')\n    ax4.set_xticks(x)\n    ax4.set_xticklabels(sensor_names, rotation=45, ha='right')\n    ax4.legend(fontsize=9)\n    ax4.grid(True, alpha=0.3, axis='y')\n    \n    # Plot 5: Error Analysis\n    ax5 = fig.add_subplot(gs[2, :])\n    stiffness_error = np.abs(pred_stiffness - true_stiffness)\n    damage_error = np.abs(pred_damage_sev - true_damage_sev)\n    \n    bars1 = ax5.bar(x - width/2, stiffness_error, width, label='Stiffness Error',\n                    color='#2E86AB', alpha=0.8, edgecolor='black')\n    bars2 = ax5.bar(x + width/2, damage_error, width, label='Damage Severity Error',\n                    color='#A23B72', alpha=0.8, edgecolor='black')\n    ax5.set_ylabel('Absolute Error', fontsize=12, fontweight='bold')\n    ax5.set_xlabel('Sensors', fontsize=12, fontweight='bold')\n    ax5.set_title('Prediction Error Analysis', fontsize=13, fontweight='bold')\n    ax5.set_xticks(x)\n    ax5.set_xticklabels(sensor_names)\n    ax5.legend(fontsize=10)\n    ax5.grid(True, alpha=0.3, axis='y')\n    \n    for bars in [bars1, bars2]:\n        for bar in bars:\n            height = bar.get_height()\n            if height > 0.01:\n                ax5.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n                        f'{height:.3f}', ha='center', va='bottom', fontsize=8)\n    \n    plt.suptitle(f'PSO Damage Localization Results - {case_name}', \n                fontsize=16, fontweight='bold', y=0.995)\n    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')\n    plt.close()\n    print(f\"   ‚úÖ Graph saved: {save_path}\")\n\ndef plot_overall_performance(all_metrics, scenarios, save_path):\n    \"\"\"Plot overall performance across all scenarios\"\"\"\n    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n    scenario_names = [s['name'] for s in scenarios]\n    \n    # Plot 1: Accuracy across scenarios\n    ax = axes[0, 0]\n    accuracies = [m['accuracy'] for m in all_metrics]\n    colors = ['#06A77D' if acc > 0.8 else '#F18F01' if acc > 0.6 else '#C73E1D' for acc in accuracies]\n    ax.bar(range(len(accuracies)), accuracies, color=colors, alpha=0.8, edgecolor='black')\n    ax.set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n    ax.set_title('Accuracy Across Scenarios', fontsize=13, fontweight='bold')\n    ax.set_xticks(range(len(scenario_names)))\n    ax.set_xticklabels(scenario_names, rotation=45, ha='right', fontsize=8)\n    ax.axhline(y=0.8, color='green', linestyle='--', alpha=0.5, label='Good (0.8)')\n    ax.axhline(y=0.6, color='orange', linestyle='--', alpha=0.5, label='Fair (0.6)')\n    ax.set_ylim(0, 1.1)\n    ax.legend()\n    ax.grid(True, alpha=0.3, axis='y')\n    \n    # Plot 2: All metrics comparison\n    ax = axes[0, 1]\n    x = np.arange(len(all_metrics))\n    width = 0.2\n    precisions = [m['precision'] for m in all_metrics]\n    recalls = [m['recall'] for m in all_metrics]\n    f1_scores = [m['f1_score'] for m in all_metrics]\n    \n    ax.bar(x - width, accuracies, width, label='Accuracy', color='#06A77D', alpha=0.8)\n    ax.bar(x, precisions, width, label='Precision', color='#F18F01', alpha=0.8)\n    ax.bar(x + width, recalls, width, label='Recall', color='#C73E1D', alpha=0.8)\n    ax.bar(x + 2*width, f1_scores, width, label='F1-Score', color='#6A4C93', alpha=0.8)\n    ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n    ax.set_title('All Metrics Comparison', fontsize=13, fontweight='bold')\n    ax.set_xticks(x + width/2)\n    ax.set_xticklabels(range(1, len(all_metrics)+1))\n    ax.set_xlabel('Scenario Number', fontsize=11, fontweight='bold')\n    ax.legend()\n    ax.grid(True, alpha=0.3, axis='y')\n    ax.set_ylim(0, 1.1)\n    \n    # Plot 3: Confusion Matrix\n    ax = axes[1, 0]\n    total_tp = sum(m['true_positives'] for m in all_metrics)\n    total_fp = sum(m['false_positives'] for m in all_metrics)\n    total_tn = sum(m['true_negatives'] for m in all_metrics)\n    total_fn = sum(m['false_negatives'] for m in all_metrics)\n    \n    confusion = np.array([[total_tn, total_fp], [total_fn, total_tp]])\n    im = ax.imshow(confusion, cmap='Blues', alpha=0.8)\n    ax.set_xticks([0, 1])\n    ax.set_yticks([0, 1])\n    ax.set_xticklabels(['Predicted Healthy', 'Predicted Damaged'], fontsize=10)\n    ax.set_yticklabels(['True Healthy', 'True Damaged'], fontsize=10)\n    ax.set_title('Cumulative Confusion Matrix', fontsize=13, fontweight='bold')\n    \n    for i in range(2):\n        for j in range(2):\n            ax.text(j, i, confusion[i, j], ha=\"center\", va=\"center\", \n                   color=\"black\", fontsize=20, fontweight='bold')\n    plt.colorbar(im, ax=ax)\n    \n    # Plot 4: Distribution\n    ax = axes[1, 1]\n    metrics_data = [accuracies, precisions, recalls, f1_scores]\n    positions = [1, 2, 3, 4]\n    ax.boxplot(metrics_data, positions=positions, widths=0.6, patch_artist=True,\n               boxprops=dict(facecolor='lightblue', alpha=0.7),\n               medianprops=dict(color='red', linewidth=2))\n    ax.set_xticklabels(['Accuracy', 'Precision', 'Recall', 'F1-Score'], fontsize=11)\n    ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n    ax.set_title('Performance Metrics Distribution', fontsize=13, fontweight='bold')\n    ax.grid(True, alpha=0.3, axis='y')\n    ax.set_ylim(0, 1.1)\n    \n    means = [np.mean(data) for data in metrics_data]\n    ax.plot(positions, means, 'D', color='green', markersize=10, label='Mean', zorder=3)\n    ax.legend()\n    \n    plt.suptitle('PSO Damage Localization - Overall Performance Analysis', \n                fontsize=16, fontweight='bold', y=0.995)\n    plt.tight_layout()\n    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')\n    plt.close()\n    print(f\"   ‚úÖ Overall performance graph: {save_path}\")\n\n# ============================================================================\n# MAIN PIPELINE\n# ============================================================================\n\ndef run_pso_simulation(healthy_paths=None, healthy_signals_tensor=None, n_particles=50, \n                      n_iterations=50, n_damage_scenarios=15, device='cuda', output_dir='pso_results'):\n    \"\"\"Run PSO simulation on multiple healthy datasets\"\"\"\n    os.makedirs(output_dir, exist_ok=True)\n    device = torch.device(device if torch.cuda.is_available() else 'cpu')\n    print(f\"üöÄ Using device: {device}\")\n    \n    sensor_names = ['Sensor_24', 'Sensor_31', 'Sensor_32']\n    max_length = 1000\n    \n    # Check if pre-computed tensor is provided\n    if healthy_signals_tensor is not None:\n        healthy_signals = healthy_signals_tensor.to(device)\n        print(f\"\\nüìä Using pre-computed healthy signals tensor\")\n        print(f\"   üìè Healthy signals shape: {healthy_signals.shape}\")\n    else:\n        # Load and normalize all healthy signals from files\n        print(f\"\\nüìä Loading {len(healthy_paths)} healthy datasets...\")\n        healthy_signals_list = []\n        \n        for path in tqdm(healthy_paths):\n            signals = load_sensor_data(path, sensor_names)\n            if signals is not None:\n                normalized_signals = []\n                for signal in signals:\n                    if len(signal) > max_length:\n                        signal = signal[:max_length]\n                    elif len(signal) < max_length:\n                        signal = np.pad(signal, (0, max_length - len(signal)), mode='constant')\n                    normalized_signals.append(signal)\n                healthy_signals_list.append(np.array(normalized_signals))\n        \n        print(f\"   ‚úÖ Successfully loaded {len(healthy_signals_list)} healthy datasets\")\n        \n        if len(healthy_signals_list) == 0:\n            raise ValueError(\"No healthy datasets loaded! Please provide valid CSV files or a healthy_signals_tensor.\")\n        \n        # Calculate ensemble baseline\n        healthy_signals_array = np.array(healthy_signals_list)\n        healthy_baseline = np.mean(healthy_signals_array, axis=0)\n        healthy_signals = torch.tensor(healthy_baseline, dtype=torch.float32).to(device)\n        print(f\"   üìè Healthy signals shape: {healthy_signals.shape}\")\n    \n    # Define damage scenarios\n    damage_scenarios = [\n        {'name': 'Single_Sensor24_Severe', 'sensors': [0], 'severity': 0.3},\n        {'name': 'Single_Sensor24_Moderate', 'sensors': [0], 'severity': 0.6},\n        {'name': 'Single_Sensor31_Severe', 'sensors': [1], 'severity': 0.3},\n        {'name': 'Single_Sensor31_Moderate', 'sensors': [1], 'severity': 0.6},\n        {'name': 'Single_Sensor32_Severe', 'sensors': [2], 'severity': 0.3},\n        {'name': 'Single_Sensor32_Moderate', 'sensors': [2], 'severity': 0.6},\n        {'name': 'Double_S24_S31_Severe', 'sensors': [0, 1], 'severity': 0.4},\n        {'name': 'Double_S24_S31_Moderate', 'sensors': [0, 1], 'severity': 0.7},\n        {'name': 'Double_S24_S32_Severe', 'sensors': [0, 2], 'severity': 0.4},\n        {'name': 'Double_S31_S32_Moderate', 'sensors': [1, 2], 'severity': 0.7},\n        {'name': 'Triple_All_Mild', 'sensors': [0, 1, 2], 'severity': 0.8},\n        {'name': 'Triple_All_Moderate', 'sensors': [0, 1, 2], 'severity': 0.6},\n        {'name': 'Triple_All_Severe', 'sensors': [0, 1, 2], 'severity': 0.4},\n        {'name': 'Single_Sensor24_Mild', 'sensors': [0], 'severity': 0.85},\n        {'name': 'Single_Sensor32_Mild', 'sensors': [2], 'severity': 0.85},\n    ]\n    \n    results = []\n    all_metrics = []\n    \n    print(f\"\\nüî¨ Running PSO on {len(damage_scenarios[:n_damage_scenarios])} damage scenarios...\\n\")\n    \n    for idx, scenario in enumerate(damage_scenarios[:n_damage_scenarios]):\n        print(f\"{'='*70}\")\n        print(f\"üîß Scenario {idx+1}/{min(n_damage_scenarios, len(damage_scenarios))}: {scenario['name']}\")\n        print(f\"{'='*70}\")\n        \n        try:\n            damaged_signals, true_damage = create_synthetic_damage(healthy_signals, scenario)\n            print(f\"   üéØ True damage: {(1 - true_damage.cpu().numpy()).round(3).tolist()}\")\n            \n            pso = BridgePSO(n_particles=n_particles, n_elements=len(sensor_names),\n                          bounds=(0.1, 1.0), c1=0.5, c2=0.3, w=0.9, device=device)\n            \n            best_damage = pso.optimize(healthy_signals, damaged_signals, n_iterations, verbose=True)\n            predicted_damage = best_damage.cpu().numpy()\n            metrics = evaluate_pso_results(predicted_damage, true_damage.cpu().numpy())\n            \n            print(f\"\\n   üìä Metrics: Acc={metrics['accuracy']:.3f}, Prec={metrics['precision']:.3f}, \"\n                  f\"Recall={metrics['recall']:.3f}, F1={metrics['f1_score']:.3f}\")\n            \n            result = {\n                'scenario': scenario['name'],\n                'true_damage_sensors': scenario['sensors'],\n                'true_severity': scenario['severity'],\n                'predicted_stiffness': predicted_damage.tolist(),\n                'predicted_damage_severity': (1.0 - predicted_damage).tolist(),\n                'final_fitness': pso.global_best_score,\n                'sensor_names': sensor_names,\n                **metrics\n            }\n            results.append(result)\n            all_metrics.append(metrics)\n            \n            save_path = os.path.join(output_dir, f\"pso_scenario_{idx+1:02d}_{scenario['name']}.png\")\n            plot_pso_results(pso.history, predicted_damage, true_damage, sensor_names, \n                           metrics, scenario['name'], save_path)\n            \n            print(f\"\\n   ‚ú® Predictions:\")\n            for sensor, pred_stiff, pred_damage in zip(sensor_names, predicted_damage, 1-predicted_damage):\n                status = \"üî¥ DAMAGED\" if pred_damage > 0.1 else \"üü¢ HEALTHY\"\n                print(f\"      {sensor}: Stiffness={pred_stiff:.3f}, Damage={pred_damage:.3f} [{status}]\")\n            \n        except Exception as e:\n            print(f\"   ‚ùå Error: {e}\")\n            continue\n    \n    # Save results\n    print(f\"\\n{'='*70}\")\n    print(\"üíæ Saving results...\")\n    print(f\"{'='*70}\")\n    \n    results_df = pd.DataFrame([{\n        'scenario': r['scenario'],\n        'true_damage_sensors': str(r['true_damage_sensors']),\n        'true_severity': r['true_severity'],\n        **{f'{sensor}_pred_stiffness': s for sensor, s in zip(sensor_names, r['predicted_stiffness'])},\n        **{f'{sensor}_pred_damage': d for sensor, d in zip(sensor_names, r['predicted_damage_severity'])},\n        'final_fitness': r['final_fitness'],\n        'accuracy': r['accuracy'],\n        'precision': r['precision'],\n        'recall': r['recall'],\n        'f1_score': r['f1_score']\n    } for r in results])\n    \n    csv_path = os.path.join(output_dir, 'pso_damage_localization_results.csv')\n    results_df.to_csv(csv_path, index=False)\n    print(f\"   ‚úÖ Results CSV: {csv_path}\")\n    \n    summary_stats = {\n        'total_scenarios': len(results),\n        'mean_accuracy': np.mean([m['accuracy'] for m in all_metrics]),\n        'mean_precision': np.mean([m['precision'] for m in all_metrics]),\n        'mean_recall': np.mean([m['recall'] for m in all_metrics]),\n        'mean_f1_score': np.mean([m['f1_score'] for m in all_metrics]),\n        'std_accuracy': np.std([m['accuracy'] for m in all_metrics]),\n        'std_precision': np.std([m['precision'] for m in all_metrics]),\n        'std_recall': np.std([m['recall'] for m in all_metrics]),\n        'std_f1_score': np.std([m['f1_score'] for m in all_metrics])\n    }\n    \n    json_path = os.path.join(output_dir, 'pso_summary_statistics.json')\n    with open(json_path, 'w') as f:\n        json.dump(summary_stats, f, indent=4)\n    print(f\"   ‚úÖ Summary JSON: {json_path}\")\n    \n    plot_overall_performance(all_metrics, damage_scenarios[:n_damage_scenarios], \n                           os.path.join(output_dir, 'pso_overall_performance.png'))\n    \n    print(f\"\\n{'='*70}\")\n    print(\"‚úÖ PSO SIMULATION COMPLETE!\")\n    print(f\"{'='*70}\")\n    print(f\"\\nüìà Overall Performance:\")\n    print(f\"   Mean Accuracy:  {summary_stats['mean_accuracy']:.4f} ¬± {summary_stats['std_accuracy']:.4f}\")\n    print(f\"   Mean Precision: {summary_stats['mean_precision']:.4f} ¬± {summary_stats['std_precision']:.4f}\")\n    print(f\"   Mean Recall:    {summary_stats['mean_recall']:.4f} ¬± {summary_stats['std_recall']:.4f}\")\n    print(f\"   Mean F1-Score:  {summary_stats['mean_f1_score']:.4f} ¬± {summary_stats['std_f1_score']:.4f}\")\n    \n    return results, summary_stats\n\n# ============================================================================\n# EXECUTION\n# ============================================================================\n\nif __name__ == \"__main__\":\n    # Example usage\n    print(\"=\"*70)\n    print(\"  PSO-BASED BRIDGE DAMAGE LOCALIZATION SYSTEM\")\n    print(\"=\"*70)\n    \n    # Find all healthy CSV files\n    healthy_csv_pattern = \"healthy_*.csv\"  # Modify this pattern as needed\n    healthy_paths = glob(healthy_csv_pattern)\n    \n    if len(healthy_paths) == 0:\n        print(\"\\n‚ö†Ô∏è  No healthy CSV files found!\")\n        print(\"   Please place healthy sensor data CSV files in the current directory\")\n        print(\"   Expected pattern: healthy_*.csv\")\n        print(\"\\n   Creating synthetic demo instead...\")\n        \n        # Create synthetic demo data\n        n_sensors = 3\n        n_samples = 1000\n        synthetic_signals = []\n        \n        for i in range(5):  # 5 synthetic healthy datasets\n            sensor_data = []\n            for s in range(n_sensors):\n                # Generate synthetic vibration signals\n                t = np.linspace(0, 10, n_samples)\n                freq = 2 + s * 0.5\n                signal = np.sin(2 * np.pi * freq * t) + np.random.normal(0, 0.1, n_samples)\n                sensor_data.append(signal)\n            synthetic_signals.append(np.array(sensor_data))\n        \n        # Convert to tensor\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        healthy_baseline = np.mean(synthetic_signals, axis=0)\n        healthy_signals = torch.tensor(healthy_baseline, dtype=torch.float32).to(device)\n        \n        print(f\"\\n‚úÖ Created synthetic healthy signals: {healthy_signals.shape}\")\n        print(f\"üöÄ Running PSO with synthetic data...\\n\")\n        \n        # Run simulation with synthetic data\n        results, summary = run_pso_simulation(\n            healthy_signals_tensor=healthy_signals,  # Pass the pre-computed tensor\n            n_particles=30,\n            n_iterations=40,\n            n_damage_scenarios=10,\n            device='cuda',\n            output_dir='pso_results_synthetic'\n        )\n        \n    else:\n        print(f\"\\n‚úÖ Found {len(healthy_paths)} healthy CSV files\")\n        print(\"   Files:\", [Path(p).name for p in healthy_paths[:5]], \"...\" if len(healthy_paths) > 5 else \"\")\n        \n        # Run simulation with real data\n        results, summary = run_pso_simulation(\n            healthy_paths=healthy_paths,\n            n_particles=50,\n            n_iterations=50,\n            n_damage_scenarios=15,\n            device='cuda',\n            output_dir='pso_results'\n        )\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"  SIMULATION COMPLETED SUCCESSFULLY!\")\n    print(\"=\"*70)\n    print(\"\\nüìÅ Check the output directory for:\")\n    print(\"   ‚Ä¢ Individual scenario plots\")\n    print(\"   ‚Ä¢ Overall performance analysis\")\n    print(\"   ‚Ä¢ Results CSV file\")\n    print(\"   ‚Ä¢ Summary statistics JSON\")\n    print(\"\\nüéâ All done!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}